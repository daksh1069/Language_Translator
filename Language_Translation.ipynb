{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Language Translation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtrIUsGg_d24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UB2ZYP1_fkN",
        "colab_type": "code",
        "outputId": "6d83bd71-bfe4-44be-942d-38f7a5389ba8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# -P For download ing/ saving file at your custom directory and not in the same directory where this code is running\n",
        "!pip install wget"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.6/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExOrw49C_fpg",
        "colab_type": "code",
        "outputId": "7017b89d-80eb-4d77-f50d-ee318c7ed982",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "! wget http://www.manythings.org/anki/deu-eng.zip "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-17 08:33:16--  http://www.manythings.org/anki/deu-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 104.24.108.196, 2606:4700:30::6818:6dc4, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7612057 (7.3M) [application/zip]\n",
            "Saving to: ‘deu-eng.zip.1’\n",
            "\n",
            "deu-eng.zip.1       100%[===================>]   7.26M  3.82MB/s    in 1.9s    \n",
            "\n",
            "2019-11-17 08:33:19 (3.82 MB/s) - ‘deu-eng.zip.1’ saved [7612057/7612057]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buvdIKZK_f5k",
        "colab_type": "code",
        "outputId": "83cef232-0b34-4292-8451-4044ef13e51d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "source": [
        "!unzip deu-eng.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  deu-eng.zip\n",
            "replace deu.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: deu.txt                 \n",
            "replace _about.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: _about.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBDvcr1t_gAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = open(\"deu.txt\", mode=\"rt\", encoding=\"utf-8\")\n",
        "data = file.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHs1ezN7_gG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_lines(text):\n",
        "  sent = text.strip().split(\"\\n\") # Every lines is split up \n",
        "  sent = [r.split(\"\\t\")  for r in sent ]\n",
        "  return sent         "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrsJVCY7_gO8",
        "colab_type": "code",
        "outputId": "bf726c21-cd84-4db9-9261-c926dd18d1dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "deu_eng = to_lines(data)\n",
        "deu_eng = np.array(deu_eng) \n",
        "deu_eng[0]                       "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Hi.', 'Hallo!',\n",
              "       'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)'],\n",
              "      dtype='<U537')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkYaAbOa_gXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "deu_eng =  deu_eng[:50000,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OX2Roag_f2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string \n",
        "deu_eng[:,0] = [s.translate(str.maketrans('','',string.punctuation)).lower() for s in deu_eng[:,0]] \n",
        "deu_eng[:,1] = [s.translate(str.maketrans('','',string.punctuation)).lower() for s in deu_eng[:,1]] \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z79ZG-XD_f0Q",
        "colab_type": "code",
        "outputId": "92a7723b-1ab2-42f0-8d97-a7a2b45dba4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "deu_eng"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['hi', 'hallo',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)'],\n",
              "       ['hi', 'grüß gott',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)'],\n",
              "       ['run', 'lauf',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #941078 (Fingerhut)'],\n",
              "       ...,\n",
              "       ['i wholeheartedly agree', 'ich stimme rückhaltlos zu',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1488273 (Spamster) & #1693172 (al_ex_an_der)'],\n",
              "       ['i will always love you', 'ich werde dich immer lieben',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #853146 (piksea) & #395302 (xtofu80)'],\n",
              "       ['i will be back by nine', 'um neun bin ich wieder zurück',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #72281 (CK) & #345033 (lilygilder)']],\n",
              "      dtype='<U537')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjyzF_39_fx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenizing all the word (split words from sentences to get induvidual words)\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "  # check this code from the link sir will provide\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cxId3pmGlUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenization(line):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(line)\n",
        "  return tokenizer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WF-I1fUsGlcq",
        "colab_type": "code",
        "outputId": "7e8e1fb1-470c-4b26-bc0a-112702c5c433",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "eng_tokenizer =  tokenization(deu_eng[:,0])\n",
        "deu_tokenizer = tokenization(deu_eng[:,1])\n",
        "\n",
        "deu_vocab_size = len(deu_tokenizer.word_index) + 1\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "\n",
        "print(len(eng_tokenizer.word_index) + 1)\n",
        "print(len(deu_tokenizer.word_index)+1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6361\n",
            "10597\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJT4VPcNGllk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras_preprocessing.sequence import pad_sequences\n",
        "\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "  seq = tokenizer.texts_to_sequences(lines)\n",
        "  seq = pad_sequences(seq, maxlen = length, padding= \"post\")\n",
        "  return seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvRnCOkHGl7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(deu_eng, test_size = 0.2, random_state = 0)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJSyMh0SGmU1",
        "colab_type": "code",
        "outputId": "8b35ee2a-b752-40a9-f61e-1e1b9da6b6c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "trainX = encode_sequences(deu_tokenizer,8,train[:, 1])\n",
        "trainY = encode_sequences(eng_tokenizer,8,train[:, 0])\n",
        "\n",
        "testX = encode_sequences(deu_tokenizer,8,test[:, 1])\n",
        "testY = encode_sequences(eng_tokenizer,8,test[:, 0])\n",
        "\n",
        "print(trainX.shape)\n",
        "print(trainX[0])\n",
        "print(trainY.shape)\n",
        "print(trainY[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40000, 8)\n",
            "[ 182   30 3286  783    0    0    0    0]\n",
            "(40000, 8)\n",
            "[  92 1255 2610    0    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx2sTfgiGmxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,LSTM,Embedding,RepeatVector\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuQH22TCOYDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(deu_vocab_size, input_length=8 ,output_dim=512))\n",
        "model.add(LSTM(512)) # Thought Vector\n",
        "model.add(RepeatVector(8)) # Repeat ho raha hai 8 baari \n",
        "model.add(LSTM(512, return_sequences=True )) # GRU layer Ki Jagah LSTM assume Kar lo abhi ke liye \n",
        "model.add(Dense( eng_vocab_size,activation = 'softmax'))\n",
        "model.compile(optimizer= optimizers.RMSprop(lr=0.001), loss='sparse_categorical_crossentropy')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHZzdGa9Gnov",
        "colab_type": "code",
        "outputId": "dc0aba6e-ae39-4050-f98d-db9e3e2972d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"model.h1 \",\n",
        "                             monitor=\"val_loss\",\n",
        "                             verbose=1, \n",
        "                             save_best_only=True,\n",
        "                             mode=\"min\")\n",
        "\n",
        "history = model.fit(trainX,\n",
        "                    trainY.reshape(trainY.shape[0],trainY.shape[1], 1),\n",
        "                    epochs=30,\n",
        "                    batch_size = 512,\n",
        "                    validation_split =0.2,\n",
        "                    callbacks = [checkpoint],\n",
        "                    verbose = 1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 32000 samples, validate on 8000 samples\n",
            "Epoch 1/30\n",
            "32000/32000 [==============================] - 17s 542us/step - loss: 3.3877 - val_loss: 2.9232\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.92320, saving model to model.h1 \n",
            "Epoch 2/30\n",
            "32000/32000 [==============================] - 15s 463us/step - loss: 2.8793 - val_loss: 2.8044\n",
            "\n",
            "Epoch 00002: val_loss improved from 2.92320 to 2.80439, saving model to model.h1 \n",
            "Epoch 3/30\n",
            "32000/32000 [==============================] - 15s 464us/step - loss: 2.7110 - val_loss: 2.7132\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.80439 to 2.71316, saving model to model.h1 \n",
            "Epoch 4/30\n",
            "32000/32000 [==============================] - 15s 463us/step - loss: 2.5802 - val_loss: 2.6011\n",
            "\n",
            "Epoch 00004: val_loss improved from 2.71316 to 2.60110, saving model to model.h1 \n",
            "Epoch 5/30\n",
            "32000/32000 [==============================] - 15s 463us/step - loss: 2.4494 - val_loss: 2.5030\n",
            "\n",
            "Epoch 00005: val_loss improved from 2.60110 to 2.50302, saving model to model.h1 \n",
            "Epoch 6/30\n",
            "32000/32000 [==============================] - 15s 463us/step - loss: 2.3308 - val_loss: 2.4288\n",
            "\n",
            "Epoch 00006: val_loss improved from 2.50302 to 2.42878, saving model to model.h1 \n",
            "Epoch 7/30\n",
            "32000/32000 [==============================] - 15s 462us/step - loss: 2.2193 - val_loss: 2.2921\n",
            "\n",
            "Epoch 00007: val_loss improved from 2.42878 to 2.29215, saving model to model.h1 \n",
            "Epoch 8/30\n",
            "32000/32000 [==============================] - 15s 460us/step - loss: 2.1138 - val_loss: 2.2235\n",
            "\n",
            "Epoch 00008: val_loss improved from 2.29215 to 2.22346, saving model to model.h1 \n",
            "Epoch 9/30\n",
            "32000/32000 [==============================] - 15s 459us/step - loss: 2.0140 - val_loss: 2.1476\n",
            "\n",
            "Epoch 00009: val_loss improved from 2.22346 to 2.14757, saving model to model.h1 \n",
            "Epoch 10/30\n",
            "32000/32000 [==============================] - 15s 461us/step - loss: 1.9143 - val_loss: 2.1020\n",
            "\n",
            "Epoch 00010: val_loss improved from 2.14757 to 2.10196, saving model to model.h1 \n",
            "Epoch 11/30\n",
            "23552/32000 [=====================>........] - ETA: 3s - loss: 1.8274"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXARGm3bGl4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "models = load_model(\"model.h1\")\n",
        "preds = models.predict_classes(testX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_834j1rlGl1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A78r9c5qGlyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUD3CySOGlvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOCUPTGuGlsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIQ0KBZZ_fwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxc-LWhs_ftZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}